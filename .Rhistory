}
}
"
# --- Model Fitting ---
model <- jags.model(textConnection(model_string),
data = data_jags,
n.chains = 3,
n.adapt = 1000)
update(model, 1000)  # burn-in
samples <- coda.samples(model,
variable.names = c("theta", "pi", "c", "alpha"),
n.iter = 5000)
samples <- coda.samples(model,
variable.names = c("alpha", "mu", "tau"),
n.iter = 5000)
# --- Summarize Results ---
summary(samples)
# Extract samples as a matrix
samples_mat <- as.matrix(samples)
# Convert mcmc.list to a matrix
samples_mat <- as.matrix(samples)
posterior_predictive <- function(samples_mat, N, K){
draw <- sample(1: nrow(samples_mat), 1)
alpha1 <- samples_mat[draw, "alpha"]
mu1 <- samples_mat[draw, "mu"]
tau1 <- samples_mat[draw, "tau"]
##
# Stick-breaking construction
v1 <- vector(length = K)
for (k in 1:K) {
v1[k] <- rbeta(1, 1, alpha1)
}
# Stick-breaking weights
pi1 <- vector(length = K)
pi1[1] <- v1[1]
for (k in 2:K) {
pi1[k] <- v1[k] * prod(1 - v1[1:(k-1)])
}
theta1 <- vector(length = K)
for (k in 1:K) {
theta1[k] <- rnorm(1, mu1, tau1)
}
c1 <- vector(length = K)
y <- vector(length = K)
for (k in 1:K) {
c1[k] <- sample(1:length(pi1), 1, prob = pi1)
p1 <- plogis(theta1[c1[k]])
y[k] <- rbinom(1, N, p1)
}
c1 <- c1[order(y)]
y <- y[order(y)]
return(list(y, c1))
}
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
remove(list = ls())
setwd("C:/Users/Caroline/Documents/MEDITWIN")
library(rjags)
library(coda)
N <- 50 #number in population for each group
# Data
Y <- c(1, 10, 20)  # successes
n <- rep(N, length(Y))   # trials
K <- length(Y) # number of arms
data_jags <- list(Y = Y, n = n, K = K)
model_string <- "
model {
# DP concentration parameter
alpha ~ dgamma(2, 1)
# Stick-breaking construction
for (k in 1:K) {
v[k] ~ dbeta(1, alpha)
}
# Stick-breaking weights
pi[1] <- v[1]
for (k in 2:K) {
pi[k] <- v[k] * prod(1 - v[1:(k-1)])
}
mu ~ dnorm(0, 1)
tau ~ dgamma(1, 0.001)
# Cluster-specific parameters (logit scale)
for (k in 1:K) {
theta[k] ~ dnorm(mu, tau)
}
# Group-level model
for (i in 1:K) {
c[i] ~ dcat(pi[])
logit(p[i]) <- theta[c[i]]
Y[i] ~ dbin(p[i], n[i])
}
}
"
# --- Model Fitting ---
model <- jags.model(textConnection(model_string),
data = data_jags,
n.chains = 3,
n.adapt = 1000)
update(model, 1000)  # burn-in
samples <- coda.samples(model,
variable.names = c("theta", "pi", "c", "alpha"),
n.iter = 5000)
samples <- coda.samples(model,
variable.names = c("alpha", "mu", "tau"),
n.iter = 5000)
# --- Summarize Results ---
summary(samples)
# Extract samples as a matrix
samples_mat <- as.matrix(samples)
posterior_predictive <- function(samples_mat, N, K){
draw <- sample(1: nrow(samples_mat), 1)
alpha1 <- samples_mat[draw, "alpha"]
mu1 <- samples_mat[draw, "mu"]
tau1 <- samples_mat[draw, "tau"]
##
# Stick-breaking construction
v1 <- vector(length = K)
for (k in 1:K) {
v1[k] <- rbeta(1, 1, alpha1)
}
# Stick-breaking weights
pi1 <- vector(length = K)
pi1[1] <- v1[1]
for (k in 2:K) {
pi1[k] <- v1[k] * prod(1 - v1[1:(k-1)])
}
theta1 <- vector(length = K)
for (k in 1:K) {
theta1[k] <- rnorm(1, mu1, tau1)
}
c1 <- vector(length = K)
y <- vector(length = K)
for (k in 1:K) {
c1[k] <- sample(1:length(pi1), 1, prob = pi1)
p1 <- plogis(theta1[c1[k]])
y[k] <- rbinom(1, N, p1)
}
c1 <- c1[order(y)]
y <- y[order(y)]
return(list(y, c1))
}
posterior_predictive(samples_mat, N, K)
len = 30
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
remove(list = ls())
setwd("C:/Users/Caroline/Documents/MEDITWIN")
library(rjags)
library(coda)
N <- 500 #number in population for each group
# Data
Y <- c(1, 10, 20)  # successes
n <- rep(N, length(Y))   # trials
K <- length(Y) # number of arms
data_jags <- list(Y = Y, n = n, K = K)
model_string <- "
model {
# DP concentration parameter
alpha ~ dgamma(2, 1)
# Stick-breaking construction
for (k in 1:K) {
v[k] ~ dbeta(1, alpha)
}
# Stick-breaking weights
pi[1] <- v[1]
for (k in 2:K) {
pi[k] <- v[k] * prod(1 - v[1:(k-1)])
}
mu ~ dnorm(0, 1)
tau ~ dgamma(1, 0.001)
# Cluster-specific parameters (logit scale)
for (k in 1:K) {
theta[k] ~ dnorm(mu, tau)
}
# Group-level model
for (i in 1:K) {
c[i] ~ dcat(pi[])
logit(p[i]) <- theta[c[i]]
Y[i] ~ dbin(p[i], n[i])
}
}
"
# --- Model Fitting ---
model <- jags.model(textConnection(model_string),
data = data_jags,
n.chains = 3,
n.adapt = 1000)
update(model, 1000)  # burn-in
samples <- coda.samples(model,
variable.names = c("theta", "pi", "c", "alpha"),
n.iter = 5000)
N <- 50 #number in population for each group
# Data
Y <- c(1, 10, 20)  # successes
n <- rep(N, length(Y))   # trials
K <- length(Y) # number of arms
data_jags <- list(Y = Y, n = n, K = K)
model_string <- "
model {
# DP concentration parameter
alpha ~ dgamma(2, 1)
# Stick-breaking construction
for (k in 1:K) {
v[k] ~ dbeta(1, alpha)
}
# Stick-breaking weights
pi[1] <- v[1]
for (k in 2:K) {
pi[k] <- v[k] * prod(1 - v[1:(k-1)])
}
mu ~ dnorm(0, 1)
tau ~ dgamma(1, 0.001)
# Cluster-specific parameters (logit scale)
for (k in 1:K) {
theta[k] ~ dnorm(mu, tau)
}
# Group-level model
for (i in 1:K) {
c[i] ~ dcat(pi[])
logit(p[i]) <- theta[c[i]]
Y[i] ~ dbin(p[i], n[i])
}
}
"
# --- Model Fitting ---
model <- jags.model(textConnection(model_string),
data = data_jags,
n.chains = 3,
n.adapt = 1000)
update(model, 1000)  # burn-in
samples <- coda.samples(model,
variable.names = c("theta", "pi", "c", "alpha"),
n.iter = 5000)
samples <- coda.samples(model,
variable.names = c("alpha", "mu", "tau"),
n.iter = 5000)
# --- Summarize Results ---
summary(samples)
# Extract samples as a matrix
samples_mat <- as.matrix(samples)
posterior_predictive <- function(samples_mat, N, K){
draw <- sample(1: nrow(samples_mat), 1)
alpha1 <- samples_mat[draw, "alpha"]
mu1 <- samples_mat[draw, "mu"]
tau1 <- samples_mat[draw, "tau"]
##
# Stick-breaking construction
v1 <- vector(length = K)
for (k in 1:K) {
v1[k] <- rbeta(1, 1, alpha1)
}
# Stick-breaking weights
pi1 <- vector(length = K)
pi1[1] <- v1[1]
for (k in 2:K) {
pi1[k] <- v1[k] * prod(1 - v1[1:(k-1)])
}
theta1 <- vector(length = K)
for (k in 1:K) {
theta1[k] <- rnorm(1, mu1, tau1)
}
c1 <- vector(length = K)
y <- vector(length = K)
for (k in 1:K) {
c1[k] <- sample(1:length(pi1), 1, prob = pi1)
p1 <- plogis(theta1[c1[k]])
y[k] <- rbinom(1, N, p1)
}
c1 <- c1[order(y)]
y <- y[order(y)]
return(list(y, c1))
}
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
colnames(samples_mat)
#########################################################################
# Bayesian cluster hierarchical model (BCHM)
# Chen N, Lee JJ. Bayesian cluster hierarchical model for subgroup borrowing in the design and analysis of basket trials with binary endpoints. Stat Methods Med Res 2020;29:2717â€“32.
# CL
#########################################################################
remove(list = ls())
setwd("C:/Users/Caroline/Documents/MEDITWIN")
library(rjags)
library(coda)
N <- 50 #number in population for each group
# Data
Y <- c(1, 10, 20)  # successes
n <- rep(N, length(Y))   # trials
K <- length(Y) # number of arms
data_jags <- list(Y = Y, n = n, K = K)
# model parameters: alpha (how many distinct groups), mu, tau (mean and variance of group clusters) #note: for binary outcomes, maybe no need for tau?
# latent variables: v, pi, theta, c, p
# observtion: Y
# JAGS Model
model_string <- "
model {
# DP concentration parameter
alpha ~ dgamma(2, 1)
# Stick-breaking construction
for (k in 1:K) {
v[k] ~ dbeta(1, alpha)
}
# Stick-breaking weights
pi[1] <- v[1]
for (k in 2:K) {
pi[k] <- v[k] * prod(1 - v[1:(k-1)])
}
mu ~ dnorm(0, 1)
tau ~ dgamma(1, 0.001)
# Cluster-specific parameters (logit scale)
for (k in 1:K) {
theta[k] ~ dnorm(mu, tau)
}
# Group-level model
for (i in 1:K) {
c[i] ~ dcat(pi[])
logit(p[i]) <- theta[c[i]]
Y[i] ~ dbin(p[i], n[i])
}
}
"
# --- Model Fitting ---
model <- jags.model(textConnection(model_string),
data = data_jags,
n.chains = 3,
n.adapt = 1000)
update(model, 1000)  # burn-in
samples <- coda.samples(model,
variable.names = c("alpha", "mu", "tau"),
n.iter = 5000)
# --- Summarize Results ---
summary(samples)
# Extract samples as a matrix
samples_mat <- as.matrix(samples)
posterior_predictive <- function(samples_mat, N, K){
draw <- sample(1: nrow(samples_mat), 1)
alpha1 <- samples_mat[draw, "alpha"]
mu1 <- samples_mat[draw, "mu"]
tau1 <- samples_mat[draw, "tau"]
##
# Stick-breaking construction
v1 <- vector(length = K)
for (k in 1:K) {
v1[k] <- rbeta(1, 1, alpha1)
}
# Stick-breaking weights
pi1 <- vector(length = K)
pi1[1] <- v1[1]
for (k in 2:K) {
pi1[k] <- v1[k] * prod(1 - v1[1:(k-1)])
}
theta1 <- vector(length = K)
for (k in 1:K) {
theta1[k] <- rnorm(1, mu1, tau1)
}
c1 <- vector(length = K)
y <- vector(length = K)
for (k in 1:K) {
c1[k] <- sample(1:length(pi1), 1, prob = pi1)
p1 <- plogis(theta1[c1[k]])
y[k] <- rbinom(1, N, p1)
}
c1 <- c1[order(y)]
y <- y[order(y)]
return(list(y, c1))
}
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
remove(list = ls())
setwd("C:/Users/Caroline/Documents/MEDITWIN")
library(rjags)
library(coda)
N <- 50 #number in population for each group
# Data
Y <- c(1, 10, 20, 50, 49)  # successes
n <- rep(N, length(Y))   # trials
K <- length(Y) # number of arms
data_jags <- list(Y = Y, n = n, K = K)
model_string <- "
model {
# DP concentration parameter
alpha ~ dgamma(2, 1)
# Stick-breaking construction
for (k in 1:K) {
v[k] ~ dbeta(1, alpha)
}
# Stick-breaking weights
pi[1] <- v[1]
for (k in 2:K) {
pi[k] <- v[k] * prod(1 - v[1:(k-1)])
}
mu ~ dnorm(0, 1)
tau ~ dgamma(1, 0.001)
# Cluster-specific parameters (logit scale)
for (k in 1:K) {
theta[k] ~ dnorm(mu, tau)
}
# Group-level model
for (i in 1:K) {
c[i] ~ dcat(pi[])
logit(p[i]) <- theta[c[i]]
Y[i] ~ dbin(p[i], n[i])
}
}
"
# --- Model Fitting ---
model <- jags.model(textConnection(model_string),
data = data_jags,
n.chains = 3,
n.adapt = 1000)
update(model, 1000)  # burn-in
samples <- coda.samples(model,
variable.names = c("alpha", "mu", "tau"),
n.iter = 5000)
# --- Summarize Results ---
summary(samples)
# Extract samples as a matrix
samples_mat <- as.matrix(samples)
posterior_predictive <- function(samples_mat, N, K){
draw <- sample(1: nrow(samples_mat), 1)
alpha1 <- samples_mat[draw, "alpha"]
mu1 <- samples_mat[draw, "mu"]
tau1 <- samples_mat[draw, "tau"]
##
# Stick-breaking construction
v1 <- vector(length = K)
for (k in 1:K) {
v1[k] <- rbeta(1, 1, alpha1)
}
# Stick-breaking weights
pi1 <- vector(length = K)
pi1[1] <- v1[1]
for (k in 2:K) {
pi1[k] <- v1[k] * prod(1 - v1[1:(k-1)])
}
theta1 <- vector(length = K)
for (k in 1:K) {
theta1[k] <- rnorm(1, mu1, tau1)
}
c1 <- vector(length = K)
y <- vector(length = K)
for (k in 1:K) {
c1[k] <- sample(1:length(pi1), 1, prob = pi1)
p1 <- plogis(theta1[c1[k]])
y[k] <- rbinom(1, N, p1)
}
c1 <- c1[order(y)]
y <- y[order(y)]
return(list(y, c1))
}
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
posterior_predictive(samples_mat, N, K)
