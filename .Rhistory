q_star<- sum(rule_probas_star)
s<- sum(dpois(2:maximum - 2,gamma1))
}
if(minimum == 1 & maximum > 1){
proba_emission_star<- proba_emission/(s*(1-proba_emission) + proba_emission)
proba_production_star<- 1 - proba_emission_star
alpha_star<- alpha2*(s*(1-proba_emission) + proba_emission)
}
if(minimum == 2){
proba_emission_star<- (1-proba_epsilon)*proba_emission/(s*(1-proba_emission)+(1-proba_epsilon)*proba_emission)
proba_production_star<- 1 - proba_emission_star
alpha_star<- alpha2*(s*(1-proba_emission) + (1-proba_epsilon)*proba_emission)
}
if(minimum > 2){
proba_emission_star<- 0
proba_production_star<- 1
alpha_star<- alpha2*s*(1-proba_emission)
}
if(maximum == 1){
proba_emission_star<- 1
proba_production_star<- 0
alpha_star<- alpha2*proba_emission*proba_epsilon
}
parameter_list<- list(proba_emission_star,proba_production_star,alpha_star,p_rules_star,q_star,qq,gamma1,proba_emission,proba_epsilon,rule_probas_star,rule_probas,rule_indices_star)
return(parameter_list)
}
p_rules1<- p_rules
weight<- 1
kernel_params<- kernel_parameters_function(nonterminal,minimum,maximum)
proba_emission_star<- kernel_params[[1]]
proba_production_star<- kernel_params[[2]]
alpha_star<- kernel_params[[3]]
p_rules_star<- kernel_params[[4]]
q_star<- kernel_params[[5]]
qq<- as.numeric(kernel_params[[6]])
gamma1<- as.numeric(kernel_params[[7]])
proba_emission<- as.numeric(kernel_params[[8]])
proba_epsilon<- as.numeric(kernel_params[[9]])
rule_probas_star<- kernel_params[[10]]
rule_probas<- kernel_params[[11]]
rule_indices_star<- kernel_params[[12]]
draw1<- sample(0:1,1,prob=c(alpha_star,q_star))
draw1==0
draw2<- sample(0:1,1,prob=c(proba_production_star,proba_emission_star))
draw2==0
nn <- maximum + 1
while (nn > maximum) {
rr <- base_production_random(nonterminal,gamma1)
nn <- rr[[5]]
#rr[[6]]<- "new"
}
rr[[6]]<- 1 #frequency
weight<- weight*rr[[7]]
rule<- rr
type<- 0
factorial(3)*factorial(3)
factorial(4)*factorial(2)
factorial(5)
n<- 100
s<- 1:n/10
s
s<- 1:(n/10)
s
s<- 1:(n/10)*10
s
y<- 2**(s-1)*(n-s+2)/n
y
plot(s,y)
n<- 1000
s<- 1:(n/10)*10
s
y<- 2**(s-1)*(n-s+2)/n
plot(s,y)
n<- 1:10*10
n
n<- 1:10*10
C<- 10
n
f <- (n+2)/(C+n)^n
plot(n,f)
?plot
n<- 1:10*10
C<- 10
n
f <- (n+2)/(C+n)^n
plot(n,f)
f
n<- 2:10*10
C<- 10
n
f <- (n)/(C+n -2)^(n-2)
n<- 2:10*10
C<- 10
n
f <- ((n)/(C+n -2))^(n-2)
plot(n,f)
n<- 2:100*10
C<- 10
n
f <- ((n)/(C+n -2))^(n-2)
plot(n,f)
n<- 60
alpha<- 3
s<- 1:n
1/(alpha^s*factorial(n-s))
plot(s,1/(alpha^s*factorial(n-s)))
n<- 100
alpha<- 3
s<- 1:n
1/(alpha^s*factorial(n-s))
plot(s,1/(alpha^s*factorial(n-s)))
n<- 1000
alpha<- 3
s<- 1:n
1/(alpha^s*factorial(n-s))
plot(s,1/(alpha^s*factorial(n-s)))
n<- 100
alpha<- 3
s<- 1:n
1/(alpha^s*factorial(n-s))
plot(s,1/(alpha^s*factorial(n-s)))
n<- 100
alpha<- 1.5
s<- 1:n
1/(alpha^s*factorial(n-s))
plot(s,1/(alpha^s*factorial(n-s)))
vec<- c(0.199,0.493,0.583,0.541,0.192,0.677,0.787,0.927,0.602,0.95,0.814,0.936,0.956,0.944,0.816,1,0.983,NA,0.852,0.995)
plot(1:20,vec)
length(vec)
vec<- c(0.199,0.493,0.583,0.541,0.192,0.677,0.787,0.927,0.602,0.95,0.814,0.936,0.956,0.944,0.816,1,0.983,NA,0.852,0.995,0.975,0.884,0.998,0.907)
length(vec)
vec<- c(0.199,0.493,0.583,0.541,0.192,0.677,0.787,0.927,0.602,0.95,0.814,0.936,0.956,0.944,0.816,1,0.983,NA,0.852,0.995,0.975,0.884,0.998,0.907)
plot(1:24,vec)
vec<- c(0.199,0.493,0.583,0.541,0.192,0.677,0.787,0.927,0.602,0.95,0.814,0.936,0.956,0.944,0.816,1,0.983,NA,0.852,0.995,0.975,0.884,0.998,0.907,0.055,0.911,0.965,0.961,0.997,0.974)
plot(1:30,vec)
1000*1.06^6
1000*1.06^7
?rgamma
rgamma(10, 200, 20)
mean(rgamma(100, 200, 20))
var(rgamma(100, 200, 20))
y = x/(x-10)+x
x = 1:9
y = x/(x-10)+x
plot(x,y)
20 - sqrt(40)
(20 - sqrt(40))/2
(20 + sqrt(40))/2
x = 1:30
y = x/(x-10)+x
plot(x,y)
e
exp(1)
exp(0.8)
4/(4+5/2^4)
4/(4+5/2^4)*52
1/3
0.98*0.98
0.98*0.98/(0.98*0.98 + 0.04*0.04)
0.98*0.98
7/12
2/3
100/1000000
exp(1-0.05)
exp(1-0.05) - exp(1) + 1
2*25*(1/3 - 1/4)
16/5
15*7
5*7
5*7*2
3*7*4
3*5*6
70=84+90
70+84+90
244/2
244+105
1/3
1/4
500/20
500/120
12000/20
600-120-100
38/4
38/2
1200/38
500/120
1000/120
5000/120
1200/5
0.4^2
0.4^2/(0.4^2+0.7^2)
n= 10
factorial(365)
factorial(365)/factorial(365-n)
factorial(3)
365*364*362*361*360/365^5
choose(4,3)
choose(10,1)
factorial(3)
factorial(4)
(1/4)^3 - (1/8)^3
8^3
4^4
4^3
512/64
80:7
80/7
factorial(8)/2/2
factorial(8)/2/2 - factorial(6)/2/3
factorial(8)/2/2 - factorial(6)/2/2
60^2 - (60-6)^2/2 - (60-24)^2/2
(60^2 - (60-6)^2/2 - (60-24)^2/2)/60^2
60^2
(60^2 - (60-6)^2/2 - (60-24)^2/2)
library(rjags)
install.packages("rjags")
library(rjags)
install.packages("rjags")
library(rjags)
install.packages("rjags")
version
install.packages("rjags")
library(rjags)
library(rjags)
# Example data
y <- c(5.1, 4.9, 5.0, 5.2, 4.8)
# JAGS model as a text string
model_string <- "
model {
for (i in 1:N) {
y[i] ~ dnorm(mu, tau)
}
mu ~ dnorm(0.0, 1.0E-6)
tau <- pow(sigma, -2)
sigma ~ dunif(0, 100)
}
"
# Save model to a file
writeLines(model_string, con = "test_model.txt")
# Data for JAGS
data_jags <- list(y = y, N = length(y))
data_jags
pwd
getwd()
data_jags
model
# Parameters to monitor
params <- c("mu", "sigma")
# Initialize and adapt model
model <- jags.model("test_model.txt",
data = data_jags,
n.chains = 3,
n.adapt = 500)
model
# Burn-in
update(model, 1000)
# Draw samples
samples <- coda.samples(model,
variable.names = params,
n.iter = 5000)
# Summary of posterior
print(summary(samples))
# Traceplot to check convergence
plot(samples)
getwd()
setwd("C:/Users/Caroline/Documents/MEDITWIN")
library(rjags)
setwd("C:/Users/Caroline/Documents/MEDITWIN")
# Example data
y <- c(5.1, 4.9, 5.0, 5.2, 4.8)
# JAGS model as a text string
model_string <- "
model {
for (i in 1:N) {
y[i] ~ dnorm(mu, tau)
}
mu ~ dnorm(0.0, 1.0E-6)
tau <- pow(sigma, -2)
sigma ~ dunif(0, 100)
}
"
# Save model to a file
writeLines(model_string, con = "test_model.txt")
# Data for JAGS
data_jags <- list(y = y, N = length(y))
# Parameters to monitor
params <- c("mu", "sigma")
# Initialize and adapt model
model <- jags.model("test_model.txt",
data = data_jags,
n.chains = 3,
n.adapt = 500)
model
# Burn-in
update(model, 1000)
# Draw samples
samples <- coda.samples(model,
variable.names = params,
n.iter = 5000)
# Summary of posterior
print(summary(samples))
# Traceplot to check convergence
plot(samples)
list.files()
remove(list = ls())
setwd("C:/Users/Caroline/Documents/MEDITWIN")
library(rjags)
library(coda)
# Example data (replace with your actual data)
Y <- c(5, 12, 7, 3, 9)          # successes in each subgroup
n <- c(10, 20, 15, 10, 18)      # trials in each subgroup
phi <- c(0.1, 0.9)              # prespecified low and high response rates
k <- length(Y)                  # number of subgroups
data_jags <- list(Y = Y, n = n, phi = phi, k = k)
tau1 ~ dgamma(0.001, 0.001)
tau2 ~ dgamma(0.001, 0.001)
tau1
tau1 = dgamma(0.001, 0.001)
tau1
tau1 = dgamma(0.001, 0.001)
tau1
logit(0.1)
rlogit(0.1)
log(0.4/(1 - 0.4))
log(0.9/(1 - 0.9))
log(0.999/(1 - 0.999))
log(0.99999/(1 - 0.99999))
log(0.9999999/(1 - 0.9999999))
remove(list = ls())
setwd("C:/Users/Caroline/Documents/MEDITWIN")
library(rjags)
library(coda)
# Example data (replace with your actual data)
Y <- c(5, 12, 7, 3, 9)          # successes in each subgroup
n <- c(10, 20, 15, 10, 18)      # trials in each subgroup
phi <- c(0.1, 0.9)              # prespecified low and high response rates
k <- length(Y)                  # number of subgroups
data_jags <- list(Y = Y, n = n, phi = phi, k = k)
model_string <- "
model {
for (j in 1:2) {
gamma[j] <- logit(phi[j])
}
tau1 ~ dgamma(0.001, 0.001)
tau2 ~ dgamma(0.001, 0.001)
for (i in 1:k) {
theta[i] ~ dnorm(0, tau2)
I[i] <- step(theta[i]) + 1
eta[i] ~ dnorm(gamma[I[i]], tau1)
logit(p[i]) <- eta[i]
Y[i] ~ dbin(p[i], n[i])
}
}
"
writeLines(model_string, con = "classification_model.txt")
remove(list = ls())
setwd("C:/Users/Caroline/Documents/MEDITWIN")
library(rjags)
library(coda)
# Example data (replace with your actual data)
Y <- c(5, 12, 7, 3, 9)          # successes in each subgroup
n <- c(10, 20, 15, 10, 18)      # trials in each subgroup
phi <- c(0.1, 0.9)              # prespecified low and high response rates
k <- length(Y)                  # number of subgroups
data_jags <- list(Y = Y, n = n, phi = phi, k = k)
model_string <- "
model {
for (j in 1:2) {
gamma[j] <- logit(phi[j])
}
tau1 ~ dgamma(0.001, 0.001)
tau2 ~ dgamma(0.001, 0.001)
for (i in 1:k) {
theta[i] ~ dnorm(0, tau2)
I[i] <- step(theta[i]) + 1
eta[i] ~ dnorm(gamma[I[i]], tau1)
logit(p[i]) <- eta[i]
Y[i] ~ dbin(p[i], n[i])
}
}
"
writeLines(model_string, con = "classification_model.txt")
model <- jags.model("classification_model.txt", data = data_jags, n.chains = 3, n.adapt = 1000)
update(model, 1000)  # burn-in
params <- c("gamma", "tau1", "tau2", "theta", "I", "p")
samples <- coda.samples(model, variable.names = params, n.iter = 5000)
samples
type(samples)
is.list(samples)
length(samples)
samples[[1]]
colnames(samples[[1]])
is.list(samples[[1]])
is.matrix(samples[[1]])
samples[[1]][,1]
count(samples[[1]][,1])
which(samples[[1]][,1] == 1)
length(which(samples[[1]][,1] == 1))/length(samples[[1]][,1])
length(which(samples[[2]][,1] == 1))/length(samples[[2]][,1])
length(which(samples[[3]][,1] == 1))/length(samples[[3]][,1])
length(which(samples[[4]][,1] == 1))/length(samples[[4]][,1])
length(which(samples[[1]][,2] == 1))/length(samples[[1]][,1])
length(which(samples[[1]][,2] == 1))/length(samples[[1]][,2])
samples <- coda.samples(model, variable.names = params, n.iter = 5000)
summary(samples)
# Extract samples as a matrix
samples_mat <- as.matrix(samples)
# Extract theta samples columns (theta[1], theta[2], ...)
theta_cols <- grep("^theta\\[", colnames(samples_mat))
# Compute posterior probability that theta_i > 0 for each subgroup
prob_theta_pos <- colMeans(samples_mat[, theta_cols] > 0)
# Set classification threshold theta_c, e.g., 0.5
theta_c <- 0.5
# Classify each subgroup
classification <- ifelse(prob_theta_pos > theta_c, "Cluster 1 (low response)", "Cluster 2 (high response)")
# Display classification
data.frame(Subgroup = 1:k,
Prob_theta_greater_0 = prob_theta_pos,
Classification = classification)
rep(10,5)
remove(list = ls())
setwd("C:/Users/Caroline/Documents/MEDITWIN")
library(rjags)
library(coda)
# Example data (replace with your actual data)
Y <- c(19, 1, 2, 19, 18)          # successes in each subgroup
n <- rep(20,5)      # trials in each subgroup
phi <- c(0.1, 0.9)              # prespecified low and high response rates
k <- length(Y)                  # number of subgroups
data_jags <- list(Y = Y, n = n, phi = phi, k = k)
model_string <- "
model {
for (j in 1:2) {
gamma[j] <- logit(phi[j])
}
tau1 ~ dgamma(0.001, 0.001)
tau2 ~ dgamma(0.001, 0.001)
for (i in 1:k) {
theta[i] ~ dnorm(0, tau2)
I[i] <- step(theta[i]) + 1
eta[i] ~ dnorm(gamma[I[i]], tau1)
logit(p[i]) <- eta[i]
Y[i] ~ dbin(p[i], n[i])
}
}
"
writeLines(model_string, con = "classification_model.txt")
model <- jags.model("classification_model.txt", data = data_jags, n.chains = 3, n.adapt = 1000)
update(model, 1000)  # burn-in
params <- c("gamma", "tau1", "tau2", "theta", "I", "p")
samples <- coda.samples(model, variable.names = params, n.iter = 5000)
summary(samples)
# Extract samples as a matrix
samples_mat <- as.matrix(samples)
# Extract theta samples columns (theta[1], theta[2], ...)
theta_cols <- grep("^theta\\[", colnames(samples_mat))
# Compute posterior probability that theta_i > 0 for each subgroup
prob_theta_pos <- colMeans(samples_mat[, theta_cols] > 0)
# Set classification threshold theta_c, e.g., 0.5
theta_c <- 0.5
# Classify each subgroup
classification <- ifelse(prob_theta_pos > theta_c, "Cluster 1 (low response)", "Cluster 2 (high response)")
# Display classification
data.frame(Subgroup = 1:k,
Prob_theta_greater_0 = prob_theta_pos,
Classification = classification)
remove(list = ls())
setwd("C:/Users/Caroline/Documents/MEDITWIN")
library(rjags)
library(coda)
# Example data (replace with your actual data)
Y <- c(19, 1, 2, 19, 10)          # successes in each subgroup
n <- rep(20,5)      # trials in each subgroup
phi <- c(0.1, 0.9)              # prespecified low and high response rates
k <- length(Y)                  # number of subgroups
data_jags <- list(Y = Y, n = n, phi = phi, k = k)
model_string <- "
model {
for (j in 1:2) {
gamma[j] <- logit(phi[j])
}
tau1 ~ dgamma(0.001, 0.001)
tau2 ~ dgamma(0.001, 0.001)
for (i in 1:k) {
theta[i] ~ dnorm(0, tau2)
I[i] <- step(theta[i]) + 1
eta[i] ~ dnorm(gamma[I[i]], tau1)
logit(p[i]) <- eta[i]
Y[i] ~ dbin(p[i], n[i])
}
}
"
writeLines(model_string, con = "classification_model.txt")
model <- jags.model("classification_model.txt", data = data_jags, n.chains = 3, n.adapt = 1000)
update(model, 1000)  # burn-in
params <- c("gamma", "tau1", "tau2", "theta", "I", "p")
samples <- coda.samples(model, variable.names = params, n.iter = 5000)
summary(samples)
# Extract samples as a matrix
samples_mat <- as.matrix(samples)
# Extract theta samples columns (theta[1], theta[2], ...)
theta_cols <- grep("^theta\\[", colnames(samples_mat))
# Compute posterior probability that theta_i > 0 for each subgroup
prob_theta_pos <- colMeans(samples_mat[, theta_cols] > 0)
# Set classification threshold theta_c, e.g., 0.5
theta_c <- 0.5
# Classify each subgroup
classification <- ifelse(prob_theta_pos > theta_c, "Cluster 1 (low response)", "Cluster 2 (high response)")
# Display classification
data.frame(Subgroup = 1:k,
Prob_theta_greater_0 = prob_theta_pos,
Classification = classification)
